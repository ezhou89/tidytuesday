---
title: "Chocolate Ratings"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width = 8, fig.height = 5)
```


*This template offers an opinionated guide on how to structure a modeling analysis. Your individual modeling analysis may require you to add to, subtract from, or otherwise change this structure, but consider this a general framework to start from. If you want to learn more about using tidymodels, check out our [Getting Started](https://www.tidymodels.org/start/) guide.*

In this example analysis, let's fit a model to predict [the sex of penguins](https://allisonhorst.github.io/palmerpenguins/) from species and measurement information.

```{r}
library(tidyverse)
library(tidymodels)

#read in data
url <- "https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-01-18/chocolate.csv"
chocolate <- read_csv(url)
chocolate %>% view()
```


## Explore data

Exploratory data analysis (EDA) is an [important part of the modeling process](https://www.tmwr.org/software-modeling.html#model-phases).

```{r}
chocolate %>%
  ggplot() + 
  aes(rating) + 
  geom_histogram(bins = 15)
```

```{r}
library(tidytext)

tidy_chocolate <- chocolate %>%
  unnest_tokens(word, most_memorable_characteristics)

tidy_chocolate %>%
  count(word, sort = TRUE)

```

```{r}
tidy_chocolate %>%
  group_by(word) %>%
  summarise(n = n(), 
            rating = mean(rating)) %>%
  ggplot() + 
  aes(x = n, y = rating) + 
  geom_point(color = "midnightblue", alpha = 0.7) + 
  geom_hline(yintercept = mean(chocolate$rating), lty = 2, color = "gray50", size = 1.5) + 
  geom_text(aes(label = word), 
            check_overlap = TRUE, vjust = "top", hjust = "left") + 
  scale_x_log10()
```


## Build models

Let's consider how to [spend our data budget](https://www.tmwr.org/splitting.html):

- create training and testing sets
- create resampling folds from the *training* set

```{r}
set.seed(123)
chocolate_split <- initial_split(chocolate, strata = rating)
chocolate_train <- training(chocolate_split)
chocolate_test <- testing(chocolate_split)

set.seed(234)
#simulated data splits
chocolate_folds <- vfold_cv(chocolate_train, strata = rating)
chocolate_folds
```

Let's set up preprocessing: 

```{r}
library(textrecipes)

choco_recipe <- recipe(rating ~ most_memorable_characteristics, 
       data = chocolate_train) %>%
  step_tokenize(most_memorable_characteristics) %>%
  step_tokenfilter(most_memorable_characteristics, max_tokens = 100) %>%
  step_tf(most_memorable_characteristics)

prep(choco_recipe)
```

```{r}
prep(choco_recipe) %>%
  bake(new_data = NULL) %>%
  skimr::skim()
```


Let's create a [**model specification**](https://www.tmwr.org/models.html) for each model we want to try:

```{r}
ranger_spec <-
  rand_forest(trees = 500) %>%
  set_engine("ranger") %>%
  set_mode("regression")

ranger_spec

svm_spec <- 
  svm_linear() %>%
  set_engine("LiblineaR") %>%
  set_mode("regression")

svm_spec
```

To set up your modeling code, consider using the [parsnip addin](https://parsnip.tidymodels.org/reference/parsnip_addin.html) or the [usemodels](https://usemodels.tidymodels.org/) package.

Now let's build a [**model workflow**](https://www.tmwr.org/workflows.html) combining each model specification with a data preprocessor:

```{r}
ranger_wf <- workflow(choco_recipe, ranger_spec)
svm_wf <- workflow(choco_recipe, svm_spec)
```

If your feature engineering needs are more complex than provided by a formula like `sex ~ .`, use a [recipe](https://www.tidymodels.org/start/recipes/). [Read more about feature engineering with recipes](https://www.tmwr.org/recipes.html) to learn how they work.


## Evaluate models

These models have no tuning parameters so we can evaluate them as they are. [Learn about tuning hyperparameters here.](https://www.tidymodels.org/start/tuning/)

```{r}
doParallel::registerDoParallel()
contrl_preds <- control_resamples(save_pred = TRUE)

svm_rs <- fit_resamples(
  svm_wf,
  resamples = chocolate_folds,
  control = contrl_preds
)

ranger_rs <- fit_resamples(
  ranger_wf,
  resamples = chocolate_folds,
  control = contrl_preds
)
```

How did these two models compare?

```{r}
collect_metrics(svm_rs)
collect_metrics(ranger_rs)
```

We can visualize these results:

```{r}
bind_rows(
  collect_predictions(svm_rs) %>%
    mutate(mod = "SVM"),
  collect_predictions(ranger_rs) %>%
    mutate(mod = "ranger")
) %>%
  ggplot() +
  aes(x = rating, y = .pred, color = id) + 
  geom_abline(lty = 2, color = "gray50", size = 1.2) + 
  geom_jitter(alpha = 0.5) + 
  facet_wrap(vars(mod)) + 
  coord_fixed()
```

These models perform very similarly, so perhaps we would choose the simpler, linear model. The function `last_fit()` *fits* one final time on the training data and *evaluates* on the testing data. This is the first time we have used the testing data.

```{r}
final_fitted <- last_fit(svm_wf, chocolate_split)
collect_metrics(final_fitted)  ## metrics evaluated on the *testing* data
```

This object contains a fitted workflow that we can use for prediction.

```{r}
final_wf <- extract_workflow(final_fitted)
predict(final_wf, chocolate_test[55,])
```

```{r}
extract_workflow(final_fitted) %>%
  tidy() %>%
  filter(term != "Bias") %>%
  group_by(estimate > 0) %>%
  slice_max(abs(estimate), n = 10)
```

```{r}
extract_workflow(final_fitted) %>%
  tidy() %>%
  filter(term != "Bias") %>%
  group_by(estimate > 0) %>%
  slice_max(abs(estimate), n = 10) %>%
  ungroup() %>%
  mutate(term = str_remove(term, "tf_most_memorable_characteristics_")) %>%
  ggplot() +
  aes(x = estimate, y = fct_reorder(term, estimate), fill = estimate > 0) + 
  geom_col(alpha = 0.8) 
```

